Q1: Define algorithmic bias and provide two examples of how it manifests

Algorithmic bias occurs when an AI system consistently produces unfair, prejudiced, or systematically skewed outcomes against certain groups. It often arises from biased training data, flawed model assumptions, or imbalanced feature representation.

Examples:

Hiring Systems Favoring Men:
Amazon’s recruitment AI downgraded CVs containing “women’s” (e.g., “women’s soccer team”) because historical data was male-dominated.

Facial Recognition Misidentifying Minorities:
Systems trained mostly on lighter-skinned faces produce higher false-positive rates for Black or Asian individuals.

Q2: Transparency vs Explainability
Transparency

Refers to the openness of the AI development process — including dataset provenance, model architecture, training procedures, and decision pipelines. It answers:
➡️ “What is inside the AI system?”

Explainability

Refers to the ability for humans to understand why an AI made a specific prediction.
It answers:
➡️ “Why did the AI make this decision?”

Why both matter

Transparency ensures trust, accountability, and regulatory compliance.

Explainability ensures human oversight, fairness evaluation, and enables debugging harmful behavior.
Together, they create a system that is auditable, trustworthy, and safe.

Q3: How GDPR impacts AI development in the EU

GDPR affects AI systems in three major ways:

Data Protection & Consent:
AI developers must obtain explicit, informed consent for collecting personal data and justify all processing activities.

Right to Explanation:
Under Articles 13–15, people can request information about automated decisions that affect them.
This increases demand for interpretable models.

Restrictions on Automated Decision-Making:
Article 22 prohibits decisions made solely by automated processing that significantly affect individuals unless safeguards are in place.

Data Minimization & Purpose Limitation:
Developers must use the least amount of data necessary, reducing risks of model overreach.

GDPR forces AI systems to be privacy-preserving, transparent, accountable, and human-centered.

✅ ETHICAL PRINCIPLES MATCHING

Match the principles:

Principle	Definition
B) Non-maleficence	Ensuring AI does not harm individuals or society.
C) Autonomy	Respecting users’ right to control their data and decisions.
D) Sustainability	Designing AI to be environmentally friendly.
A) Justice	Fair distribution of AI benefits and risks.